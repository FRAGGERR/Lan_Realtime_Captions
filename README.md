Sure! Here's a complete `README.md` for your **LAN Real-Time Captions** project, written in Markdown:

```markdown
# ğŸ¤ LAN Real-Time Captions

A lightweight, fast, and offline-ready real-time speech-to-text captioning system over LAN using **Gradio**, **FastAPI**, and **Faster-Whisper**. Built for local environments, workshops, classrooms, or meetings â€” where accurate and fast transcriptions are needed without internet dependency.

---

## ğŸš€ Features

- ğŸ™ï¸ **Speaker Interface** to capture audio and stream it for real-time transcription
- ğŸ“º **Viewer Interface** to display captions live via WebSocket
- âš¡ Uses [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) for fast and efficient transcription
- ğŸ’¾ Save and ğŸ“‚ Clear caption logs to a local CSV file
- ğŸŒ Runs on LAN â€” no cloud, no API keys, full privacy

---

## ğŸ§± Project Structure

```

lan\_realtime\_captions/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ buffer.py              # Caption buffer manager
â”‚   â”œâ”€â”€ server.py              # FastAPI server + WebSocket broadcaster
â”‚   â”œâ”€â”€ transcriber.py         # Audio transcription using Faster-Whisper
â”‚   â””â”€â”€ requirements.txt       # Backend dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ frontend.py            # Gradio UI: Speaker & Viewer
â”‚   â”œâ”€â”€ saved\_captions/
â”‚   â”‚   â””â”€â”€ database.csv       # Auto-generated CSV of saved captions
â”‚   â””â”€â”€ requirements.txt       # Frontend dependencies
â”‚
â”œâ”€â”€ venv/                      # Python virtual environment (gitignored)
â”œâ”€â”€ run.sh                     # Script to start both frontend and backend
â””â”€â”€ README.md                  # You're here ğŸ“„

````

---

## âš™ï¸ Installation & Setup

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/lan_realtime_captions.git
cd lan_realtime_captions
````

### 2. Create & activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate   # On Windows use `venv\Scripts\activate`
```

### 3. Install dependencies

```bash
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
```

> ğŸ’¡ **Note:** This uses `faster-whisper`, which supports CPU and GPU (optional).

### 4. Run the app

```bash
./run.sh
```

* Backend (FastAPI): [http://localhost:8000](http://localhost:8000)
* Frontend (Gradio): [http://localhost:7860](http://localhost:7860)

---

## ğŸ“¦ Backend API

* `POST /stream` â†’ Accepts 2-sec audio chunks, returns transcribed text
* `GET /` â†’ Returns welcome message
* `POST /transcribe` â†’ (Optional) Accepts full audio files
* `WS /ws` â†’ WebSocket broadcasting live captions to connected clients

---

## ğŸ–¥ï¸ UI Walkthrough

### ğŸ™ï¸ Speaker Tab

* Start/Stop streaming microphone audio
* Sends 2-second chunks to the backend
* Backend returns transcriptions and broadcasts them to viewers

### ğŸ“º Viewer Tab

* Displays captions in real-time
* Save current session captions to CSV
* Clear live captions

---

## ğŸ§  Model Info

* Model used: `small.en` (244 MB) by default
* Can be changed in `transcriber.py` via `MODEL_NAME = "base.en"` or others
* Runs on **CPU** or **CUDA GPU** (auto-configurable)

---

## ğŸ“ Output

Saved captions are stored in:

```
frontend/saved_captions/database.csv
```

With format:

```csv
timestamp,caption
2025-07-03 22:15:12,"Hello everyone, welcome to the session..."
```

---

## ğŸ› ï¸ TODO / Ideas

* Add language selector for multi-lingual support
* Allow saving .txt or .srt format
* Improve noise filtering for better accuracy
* Add client authentication for viewer tab

---

## ğŸ“„ License

MIT License Â© 2025 Hardik Chhipa

---

## ğŸ™ Acknowledgements

* [Gradio](https://www.gradio.app/)
* [FastAPI](https://fastapi.tiangolo.com/)
* [Faster-Whisper](https://github.com/guillaumekln/faster-whisper)
* [pydub](https://github.com/jiaaro/pydub)

```

Let me know if you'd like me to automatically insert your GitHub repo link in this `README.md`.
```
